{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rolled-charles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "tensor([[2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.]], device='cuda:0')\n",
      "tensor([[2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "x = torch.ones(5, 5)\n",
    "\n",
    "print(x)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abroad-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"I ate dinner.\", \n",
    "       \"We had a three-course meal.\", \n",
    "       \"Brad came to dinner with us.\",\n",
    "       \"He loves fish tacos.\",\n",
    "       \"In the end, we all felt like we ate too much.\",\n",
    "       \"We all agreed; it was a magnificent evening.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "several-producer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/minanaghshnejad/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "asian-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minute-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "universal-latino",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "three-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = model(sentences)\n",
    "query = \"I had pizza and pasta\"\n",
    "query_vec = model([query])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "celtic-palestinian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence =  I ate dinner. ; similarity =  0.46866417\n",
      "Sentence =  We had a three-course meal. ; similarity =  0.35643065\n",
      "Sentence =  Brad came to dinner with us. ; similarity =  0.20338944\n",
      "Sentence =  He loves fish tacos. ; similarity =  0.16515437\n",
      "Sentence =  In the end, we all felt like we ate too much. ; similarity =  0.14987424\n",
      "Sentence =  We all agreed; it was a magnificent evening. ; similarity =  0.05843591\n"
     ]
    }
   ],
   "source": [
    "for sent in sentences:\n",
    "    sim = cosine(query_vec, model([sent])[0])\n",
    "    print(\"Sentence = \", sent, \"; similarity = \", sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "planned-mexican",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (summarizer.py, line 241)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/minanaghshnejad/python_projects/my_project_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3437\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-d03d0499e177>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from summarizer import USERank\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/minanaghshnejad/python_projects/Extractive-Domain-Independent-Graph-Based-Multi-Document-Text-Summarization-master/summarizer.py\"\u001b[0;36m, line \u001b[0;32m241\u001b[0m\n\u001b[0;31m    if stopwords is None:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "from summarizer import USERank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#from summarizer import LexRank\n",
    "\n",
    "from path import Path\n",
    "from myRouge import rouge_1\n",
    "import rouge\n",
    "import nltk.data\n",
    "#from keyPhraseExtractor import KeyPhraseExtractor\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = \"National Archives NEWLINE_CHAR  NEWLINE_CHAR Yes, it’s that time again, folks. It’s the first Friday of the month, when for one ever-so-brief moment the interests of Wall Street, Washington and Main Street are all aligned on one thing: Jobs. NEWLINE_CHAR  NEWLINE_CHAR A fresh update on the U.S. employment situation for January hits the wires at 8:30 a.m. New York time offering one of the most important snapshots on how the economy fared during the previous month. Expectations are for 203,000 new jobs to be created, according to economists polled by Dow Jones Newswires, compared to 227,000 jobs added in February. The unemployment rate is expected to hold steady at 8.3%. NEWLINE_CHAR  NEWLINE_CHAR Here at MarketBeat HQ, we’ll be offering color commentary before and after the data crosses the wires. Feel free to weigh-in yourself, via the comments section. And while you’re here, why don’t you sign up to follow us on Twitter. NEWLINE_CHAR  NEWLINE_CHAR Enjoy the show. ||||| Employers pulled back sharply on hiring last month, a reminder that the U.S. economy may not be growing fast enough to sustain robust job growth. The unemployment rate dipped, but mostly because more Americans stopped looking for work. NEWLINE_CHAR  NEWLINE_CHAR The Labor Department says the economy added 120,000 jobs in March, down from more than 200,000 in each of the previous three months. NEWLINE_CHAR  NEWLINE_CHAR The unemployment rate fell to 8.2 percent, the lowest since January 2009. The rate dropped because fewer people searched for jobs. The official unemployment tally only includes those seeking work. NEWLINE_CHAR  NEWLINE_CHAR The economy has added 858,000 jobs since December _ the best four months of hiring in two years. But Federal Reserve Chairman Ben Bernanke has cautioned that the current hiring pace is unlikely to continue without more consumer spending. |||||\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ='The unemployment rate dropped to 8.2% last month, but the economy only added 120,000 jobs, when 203,000 new jobs had been predicted, according to todays jobs report. Reaction on the Wall Street Journals MarketBeat Blog was swift: \"Woah!!! Bad number.\" The unemployment rate, however, is better news; it had been expected to hold steady at 8.3%. But the AP notes that the dip is mostly due to more Americans giving up on seeking employment.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "use = USERank(texts,model, stopwords=stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "produced_summary=lxr.get_summary(sentences, summary_size=6, threshold=None, include_keyphrase_similarity = False, redunduncy_penalty = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "producedSummary = ' '.join(produced_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSummarySentences = tokenizer.tokenize(summ)\n",
    "modelSummary = ' '.join(modelSummarySentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rouge_1(producedSummary, modelSummary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
